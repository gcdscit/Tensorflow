{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading all necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "import keras as kr\n",
    "kr.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 11001] getaddrinfo failed>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1317\u001b[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[1;32m-> 1318\u001b[1;33m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0m\u001b[0;32m   1319\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1238\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1284\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1233\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1234\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1025\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1026\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    963\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 964\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    965\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    935\u001b[0m         self.sock = self._create_connection(\n\u001b[1;32m--> 936\u001b[1;33m             (self.host,self.port), self.timeout, self.source_address)\n\u001b[0m\u001b[0;32m    937\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIPPROTO_TCP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTCP_NODELAY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    703\u001b[0m     \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSOCK_STREAM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    744\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 745\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    746\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-68831933a301>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Loading and viewing iris dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[0mcompression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_infer_compression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m     filepath_or_buffer, _, compression = get_filepath_or_buffer(\n\u001b[1;32m--> 392\u001b[1;33m         filepath_or_buffer, encoding, compression)\n\u001b[0m\u001b[0;32m    393\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'compression'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression)\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_urlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m         \u001b[0mcontent_encoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Content-Encoding'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'gzip'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    524\u001b[0m             \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    542\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[1;32m--> 544\u001b[1;33m                                   '_open', req)\n\u001b[0m\u001b[0;32m    545\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    502\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1359\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[1;32m-> 1361\u001b[1;33m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[0;32m   1362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1318\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0;32m   1319\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1320\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1321\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [Errno 11001] getaddrinfo failed>"
     ]
    }
   ],
   "source": [
    "#Loading and viewing iris dataset\n",
    "dataset = pd.read_csv(\"https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset.values[:, 0:4]\n",
    "y = dataset.values[:, 4]\n",
    "X.shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder =  LabelEncoder()\n",
    "y1 = encoder.fit_transform(y)\n",
    "\n",
    "Y = pd.get_dummies(y1).values\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining the model \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD,Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 15\n",
      "Trainable params: 15\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Input and Output layers directly connected network\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=3, activation='softmax', input_dim=4))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "120/120 [==============================] - 0s 105us/step - loss: 0.6932 - acc: 0.7000\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 79us/step - loss: 0.6915 - acc: 0.7000\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 68us/step - loss: 0.6895 - acc: 0.7000\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 76us/step - loss: 0.6875 - acc: 0.6917\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 85us/step - loss: 0.6857 - acc: 0.6917\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 96us/step - loss: 0.6838 - acc: 0.6917\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 70us/step - loss: 0.6820 - acc: 0.7000\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 105us/step - loss: 0.6801 - acc: 0.7000\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 94us/step - loss: 0.6784 - acc: 0.7000\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 104us/step - loss: 0.6766 - acc: 0.7000\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.6747 - acc: 0.7000\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 72us/step - loss: 0.6733 - acc: 0.6917\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 95us/step - loss: 0.6712 - acc: 0.6917\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 99us/step - loss: 0.6696 - acc: 0.6917\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 104us/step - loss: 0.6679 - acc: 0.7000\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.6662 - acc: 0.7000\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 101us/step - loss: 0.6644 - acc: 0.7000\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 113us/step - loss: 0.6629 - acc: 0.7000\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 99us/step - loss: 0.6612 - acc: 0.7000\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 93us/step - loss: 0.6595 - acc: 0.7000\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 60us/step - loss: 0.6579 - acc: 0.7000\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 80us/step - loss: 0.6562 - acc: 0.7000\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 82us/step - loss: 0.6548 - acc: 0.7000\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 89us/step - loss: 0.6530 - acc: 0.7000\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 78us/step - loss: 0.6515 - acc: 0.7000\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 122us/step - loss: 0.6500 - acc: 0.7000\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 95us/step - loss: 0.6484 - acc: 0.7000\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 87us/step - loss: 0.6468 - acc: 0.7000\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 60us/step - loss: 0.6453 - acc: 0.7000\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 83us/step - loss: 0.6438 - acc: 0.7000\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 149us/step - loss: 0.6423 - acc: 0.7000\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 108us/step - loss: 0.6407 - acc: 0.7000\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 122us/step - loss: 0.6393 - acc: 0.7000\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 100us/step - loss: 0.6378 - acc: 0.7000\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 107us/step - loss: 0.6365 - acc: 0.7000\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.6349 - acc: 0.7083\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 90us/step - loss: 0.6335 - acc: 0.7083\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 102us/step - loss: 0.6321 - acc: 0.7083\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.6308 - acc: 0.7083\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 96us/step - loss: 0.6294 - acc: 0.7083\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.6281 - acc: 0.7083\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 78us/step - loss: 0.6266 - acc: 0.7083\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.6253 - acc: 0.7083\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 64us/step - loss: 0.6239 - acc: 0.7083\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 105us/step - loss: 0.6224 - acc: 0.7083\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 79us/step - loss: 0.6210 - acc: 0.7083\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 70us/step - loss: 0.6199 - acc: 0.7083\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 113us/step - loss: 0.6184 - acc: 0.7083\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 76us/step - loss: 0.6172 - acc: 0.7167\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 98us/step - loss: 0.6158 - acc: 0.7167\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 94us/step - loss: 0.6145 - acc: 0.7167\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.6133 - acc: 0.7167\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 117us/step - loss: 0.6120 - acc: 0.7167\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 67us/step - loss: 0.6107 - acc: 0.7167\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 62us/step - loss: 0.6094 - acc: 0.7167\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 118us/step - loss: 0.6083 - acc: 0.7167\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 63us/step - loss: 0.6070 - acc: 0.7250\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 67us/step - loss: 0.6058 - acc: 0.7250\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 99us/step - loss: 0.6045 - acc: 0.7250\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 88us/step - loss: 0.6033 - acc: 0.7250\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 94us/step - loss: 0.6021 - acc: 0.7250\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 85us/step - loss: 0.6009 - acc: 0.7333\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 93us/step - loss: 0.5997 - acc: 0.7333\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.5986 - acc: 0.7333\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 123us/step - loss: 0.5973 - acc: 0.7333\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 95us/step - loss: 0.5963 - acc: 0.7417\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 123us/step - loss: 0.5950 - acc: 0.7333\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 53us/step - loss: 0.5939 - acc: 0.7333\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 100us/step - loss: 0.5928 - acc: 0.7333\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 88us/step - loss: 0.5918 - acc: 0.7333\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 124us/step - loss: 0.5905 - acc: 0.7333\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 55us/step - loss: 0.5895 - acc: 0.7333\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 130us/step - loss: 0.5883 - acc: 0.7417\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 98us/step - loss: 0.5872 - acc: 0.7417\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 86us/step - loss: 0.5860 - acc: 0.7417\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 86us/step - loss: 0.5852 - acc: 0.7417\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 61us/step - loss: 0.5839 - acc: 0.7417\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 103us/step - loss: 0.5831 - acc: 0.7417\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 115us/step - loss: 0.5818 - acc: 0.7417\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 95us/step - loss: 0.5808 - acc: 0.7417\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 84us/step - loss: 0.5799 - acc: 0.7417\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.5789 - acc: 0.7417\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 76us/step - loss: 0.5776 - acc: 0.7417\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 115us/step - loss: 0.5765 - acc: 0.7417\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 89us/step - loss: 0.5755 - acc: 0.7417\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 98us/step - loss: 0.5745 - acc: 0.7417\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 77us/step - loss: 0.5735 - acc: 0.7417\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.5725 - acc: 0.7417\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 92us/step - loss: 0.5715 - acc: 0.7417\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 104us/step - loss: 0.5705 - acc: 0.7417\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 80us/step - loss: 0.5700 - acc: 0.7417\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 123us/step - loss: 0.5687 - acc: 0.7417\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 112us/step - loss: 0.5675 - acc: 0.7417\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 89us/step - loss: 0.5667 - acc: 0.7417\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 106us/step - loss: 0.5656 - acc: 0.7500\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 107us/step - loss: 0.5647 - acc: 0.7417\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 111us/step - loss: 0.5637 - acc: 0.7417\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 89us/step - loss: 0.5627 - acc: 0.7417\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 122us/step - loss: 0.5620 - acc: 0.7417\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 83us/step - loss: 0.5608 - acc: 0.7417\n"
     ]
    }
   ],
   "source": [
    "#Calculating accuracy for Input and Output layer directly connected network\n",
    "\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_test_class = np.argmax(y_test,axis=1)\n",
    "y_pred_class = np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       0.75      0.23      0.35        13\n",
      "          2       0.33      0.83      0.48         6\n",
      "\n",
      "avg / total       0.76      0.63      0.61        30\n",
      "\n",
      "[[11  0  0]\n",
      " [ 0  3 10]\n",
      " [ 0  1  5]]\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of the predicted values of model without hidden layers\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test_class,y_pred_class))\n",
    "print(confusion_matrix(y_test_class,y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 83\n",
      "Trainable params: 83\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Adding Single hidden layer with 10 neurons\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Dense(10,input_shape=(4,),activation='relu'))\n",
    "model1.add(Dense(3,activation='softmax'))\n",
    "model1.compile(Adam(lr=0.04),'categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 1.7807 - acc: 0.2083\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 171us/step - loss: 1.1697 - acc: 0.2417\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 175us/step - loss: 0.8824 - acc: 0.5583\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 78us/step - loss: 0.7254 - acc: 0.5833\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 108us/step - loss: 0.6148 - acc: 0.6167\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 117us/step - loss: 0.5337 - acc: 0.6917\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 54us/step - loss: 0.4860 - acc: 0.8417\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 113us/step - loss: 0.4277 - acc: 0.8083\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 151us/step - loss: 0.3825 - acc: 0.8500\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 118us/step - loss: 0.3533 - acc: 0.9167\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 123us/step - loss: 0.3165 - acc: 0.9250\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 87us/step - loss: 0.3145 - acc: 0.8917\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 94us/step - loss: 0.2593 - acc: 0.9167\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 67us/step - loss: 0.2419 - acc: 0.9417\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 76us/step - loss: 0.2115 - acc: 0.9333\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 112us/step - loss: 0.2056 - acc: 0.9417\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 85us/step - loss: 0.1751 - acc: 0.9333\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 86us/step - loss: 0.1636 - acc: 0.9500\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 123us/step - loss: 0.1499 - acc: 0.9583\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 96us/step - loss: 0.1373 - acc: 0.9667\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 96us/step - loss: 0.1340 - acc: 0.9583\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 89us/step - loss: 0.1279 - acc: 0.9583\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 146us/step - loss: 0.1205 - acc: 0.9583\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 92us/step - loss: 0.1160 - acc: 0.9667\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 99us/step - loss: 0.1246 - acc: 0.9333\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.1187 - acc: 0.9583\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 100us/step - loss: 0.0994 - acc: 0.9667\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 118us/step - loss: 0.0992 - acc: 0.9750\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 83us/step - loss: 0.0949 - acc: 0.9667\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 92us/step - loss: 0.1028 - acc: 0.9583\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 67us/step - loss: 0.1266 - acc: 0.9500\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 82us/step - loss: 0.1199 - acc: 0.9417\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 156us/step - loss: 0.0817 - acc: 0.9667\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 81us/step - loss: 0.1065 - acc: 0.9583\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 123us/step - loss: 0.1022 - acc: 0.9583\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 87us/step - loss: 0.0843 - acc: 0.9750\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 89us/step - loss: 0.0775 - acc: 0.9750\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.0883 - acc: 0.9667\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 105us/step - loss: 0.0897 - acc: 0.9667\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 87us/step - loss: 0.0790 - acc: 0.9750\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.0872 - acc: 0.9667\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 83us/step - loss: 0.0928 - acc: 0.9667\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 116us/step - loss: 0.0924 - acc: 0.9667\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 92us/step - loss: 0.0807 - acc: 0.9667\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.0881 - acc: 0.9750\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 64us/step - loss: 0.1309 - acc: 0.9500\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 84us/step - loss: 0.1242 - acc: 0.9417\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 66us/step - loss: 0.0910 - acc: 0.9667\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.1011 - acc: 0.9500\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 100us/step - loss: 0.1285 - acc: 0.9583\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 114us/step - loss: 0.1308 - acc: 0.9333\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 61us/step - loss: 0.0826 - acc: 0.9750\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 137us/step - loss: 0.0836 - acc: 0.9667\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 80us/step - loss: 0.1031 - acc: 0.9500\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 56us/step - loss: 0.0793 - acc: 0.9833\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 68us/step - loss: 0.0927 - acc: 0.9583\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 87us/step - loss: 0.1230 - acc: 0.9500\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 101us/step - loss: 0.1025 - acc: 0.9583\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 62us/step - loss: 0.0797 - acc: 0.9583\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 68us/step - loss: 0.1025 - acc: 0.9500\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 117us/step - loss: 0.0902 - acc: 0.9750\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 69us/step - loss: 0.0814 - acc: 0.9667\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 112us/step - loss: 0.0771 - acc: 0.9667\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 125us/step - loss: 0.0694 - acc: 0.9750\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 69us/step - loss: 0.0744 - acc: 0.9750\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 89us/step - loss: 0.0779 - acc: 0.9667\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 77us/step - loss: 0.0934 - acc: 0.9667\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 77us/step - loss: 0.0762 - acc: 0.9750\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 79us/step - loss: 0.1305 - acc: 0.9417\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 63us/step - loss: 0.0699 - acc: 0.9667\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 82us/step - loss: 0.0718 - acc: 0.9750\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 96us/step - loss: 0.0800 - acc: 0.9583\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 62us/step - loss: 0.0752 - acc: 0.9583\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 63us/step - loss: 0.0908 - acc: 0.9583\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 85us/step - loss: 0.0736 - acc: 0.9667\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 84us/step - loss: 0.0944 - acc: 0.9500\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.0655 - acc: 0.9583\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 90us/step - loss: 0.0803 - acc: 0.9667\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 61us/step - loss: 0.1135 - acc: 0.9500\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 80us/step - loss: 0.0707 - acc: 0.9750\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 95us/step - loss: 0.0604 - acc: 0.9750\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 78us/step - loss: 0.0714 - acc: 0.9667\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 81us/step - loss: 0.0694 - acc: 0.9750\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.0663 - acc: 0.9667\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 89us/step - loss: 0.0644 - acc: 0.9750\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 66us/step - loss: 0.0723 - acc: 0.9667\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 87us/step - loss: 0.0675 - acc: 0.9667\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0504 - acc: 0.968 - 0s 68us/step - loss: 0.0640 - acc: 0.9667\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 63us/step - loss: 0.0766 - acc: 0.9667\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 78us/step - loss: 0.0977 - acc: 0.9667\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 117us/step - loss: 0.1078 - acc: 0.9583\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 113us/step - loss: 0.0647 - acc: 0.9667\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 120us/step - loss: 0.1071 - acc: 0.9417\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 94us/step - loss: 0.1157 - acc: 0.9500\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 124us/step - loss: 0.1241 - acc: 0.9500\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 107us/step - loss: 0.1223 - acc: 0.9583\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 95us/step - loss: 0.1310 - acc: 0.9417\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 83us/step - loss: 0.0591 - acc: 0.9833\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 67us/step - loss: 0.1138 - acc: 0.9583\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 117us/step - loss: 0.0759 - acc: 0.9583\n"
     ]
    }
   ],
   "source": [
    "#Calculating accuracy for Single hidden layer NN\n",
    "\n",
    "model1.fit(X_train,y_train,epochs=100)\n",
    "y_pred = model1.predict(X_test)\n",
    "\n",
    "y_test_class = np.argmax(y_test,axis=1)\n",
    "y_pred_class = np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        13\n",
      "          2       1.00      1.00      1.00         6\n",
      "\n",
      "avg / total       1.00      1.00      1.00        30\n",
      "\n",
      "[[11  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0  6]]\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of the predicted values from Model1 with one hidden layer\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test_class,y_pred_class))\n",
    "print(confusion_matrix(y_test_class,y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 213\n",
      "Trainable params: 213\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Adding Three hidden layers to network\n",
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Dense(10,input_shape=(4,),activation='tanh'))\n",
    "model2.add(Dense(8,activation='tanh'))\n",
    "model2.add(Dense(6,activation='tanh'))\n",
    "model2.add(Dense(3,activation='softmax'))\n",
    "\n",
    "model2.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics = ['accuracy'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.0728 - acc: 0.9667\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 72us/step - loss: 0.0652 - acc: 0.9750\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 108us/step - loss: 0.0628 - acc: 0.9833\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 106us/step - loss: 0.0599 - acc: 0.9833\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 115us/step - loss: 0.0598 - acc: 0.9833\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 92us/step - loss: 0.0750 - acc: 0.9667\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 92us/step - loss: 0.0908 - acc: 0.9583\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 94us/step - loss: 0.0964 - acc: 0.9583\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 89us/step - loss: 0.1314 - acc: 0.9667\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 134us/step - loss: 0.0673 - acc: 0.9667\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 91us/step - loss: 0.0832 - acc: 0.9583\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 84us/step - loss: 0.1309 - acc: 0.9583\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 78us/step - loss: 0.0798 - acc: 0.9833\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 97us/step - loss: 0.0803 - acc: 0.9667\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 96us/step - loss: 0.0999 - acc: 0.9500\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 100us/step - loss: 0.0657 - acc: 0.9750\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 72us/step - loss: 0.0626 - acc: 0.9833\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 92us/step - loss: 0.0615 - acc: 0.9750\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 69us/step - loss: 0.0681 - acc: 0.9750\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 87us/step - loss: 0.0661 - acc: 0.9750\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 88us/step - loss: 0.0643 - acc: 0.9833\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 143us/step - loss: 0.0824 - acc: 0.9583\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 76us/step - loss: 0.0668 - acc: 0.9750\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 94us/step - loss: 0.0631 - acc: 0.9750\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 94us/step - loss: 0.0616 - acc: 0.9750\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 69us/step - loss: 0.0669 - acc: 0.9750\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 103us/step - loss: 0.0756 - acc: 0.9667\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 113us/step - loss: 0.0742 - acc: 0.9750\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 63us/step - loss: 0.0618 - acc: 0.9750\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 95us/step - loss: 0.0591 - acc: 0.9750\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 79us/step - loss: 0.0589 - acc: 0.9833\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 88us/step - loss: 0.0652 - acc: 0.9667\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 131us/step - loss: 0.0630 - acc: 0.9833\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.0627 - acc: 0.9750\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 84us/step - loss: 0.0894 - acc: 0.9583\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.0692 - acc: 0.9750\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 140us/step - loss: 0.0608 - acc: 0.9750\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 112us/step - loss: 0.0630 - acc: 0.9667\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 107us/step - loss: 0.0644 - acc: 0.9750\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 62us/step - loss: 0.0655 - acc: 0.9667\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 94us/step - loss: 0.0633 - acc: 0.9750\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 60us/step - loss: 0.0675 - acc: 0.9750\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 103us/step - loss: 0.0736 - acc: 0.9750\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 80us/step - loss: 0.0633 - acc: 0.9833\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 63us/step - loss: 0.0743 - acc: 0.9750\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 78us/step - loss: 0.0639 - acc: 0.9833\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 113us/step - loss: 0.0725 - acc: 0.9750\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 85us/step - loss: 0.1325 - acc: 0.9583\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 69us/step - loss: 0.1094 - acc: 0.9500\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 64us/step - loss: 0.0658 - acc: 0.9583\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 104us/step - loss: 0.1174 - acc: 0.9583\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 69us/step - loss: 0.1296 - acc: 0.9667\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 62us/step - loss: 0.1201 - acc: 0.9583\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 80us/step - loss: 0.1069 - acc: 0.9583\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 111us/step - loss: 0.0787 - acc: 0.9667\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 82us/step - loss: 0.0989 - acc: 0.9583\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 115us/step - loss: 0.0762 - acc: 0.9667\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 67us/step - loss: 0.0726 - acc: 0.9667\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 72us/step - loss: 0.0675 - acc: 0.9833\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 70us/step - loss: 0.0724 - acc: 0.9750\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 67us/step - loss: 0.0669 - acc: 0.9750\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 92us/step - loss: 0.0615 - acc: 0.9833\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 110us/step - loss: 0.0643 - acc: 0.9833\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 89us/step - loss: 0.0631 - acc: 0.9750\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 54us/step - loss: 0.0707 - acc: 0.9750\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 114us/step - loss: 0.0585 - acc: 0.9750\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 69us/step - loss: 0.0656 - acc: 0.9667\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 92us/step - loss: 0.0862 - acc: 0.9583\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 95us/step - loss: 0.0612 - acc: 0.9833\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 78us/step - loss: 0.0669 - acc: 0.9583\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 62us/step - loss: 0.0555 - acc: 0.9750\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 91us/step - loss: 0.0942 - acc: 0.9583\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 89us/step - loss: 0.0622 - acc: 0.9667\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 91us/step - loss: 0.0603 - acc: 0.9833\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 79us/step - loss: 0.0628 - acc: 0.9667\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 102us/step - loss: 0.0566 - acc: 0.9750\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 120us/step - loss: 0.0750 - acc: 0.9667\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 88us/step - loss: 0.0552 - acc: 0.9750\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 69us/step - loss: 0.0695 - acc: 0.9833\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 102us/step - loss: 0.0536 - acc: 0.9750\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 70us/step - loss: 0.0739 - acc: 0.9750\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.0577 - acc: 0.9667\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.0685 - acc: 0.9833\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 100us/step - loss: 0.0704 - acc: 0.9583\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 61us/step - loss: 0.0504 - acc: 0.9750\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 62us/step - loss: 0.0710 - acc: 0.9667\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 83us/step - loss: 0.0599 - acc: 0.9833\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 62us/step - loss: 0.0657 - acc: 0.9667\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 94us/step - loss: 0.0526 - acc: 0.9833\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 139us/step - loss: 0.0708 - acc: 0.9750\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.0674 - acc: 0.9667\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 123us/step - loss: 0.0551 - acc: 0.9833\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 85us/step - loss: 0.0701 - acc: 0.9667\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 93us/step - loss: 0.0923 - acc: 0.9583\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 120us/step - loss: 0.0878 - acc: 0.9583\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 130us/step - loss: 0.0545 - acc: 0.9750\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 135us/step - loss: 0.1276 - acc: 0.9500\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0465 - acc: 0.968 - 0s 95us/step - loss: 0.0668 - acc: 0.9583\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 111us/step - loss: 0.0706 - acc: 0.9583\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 100us/step - loss: 0.0826 - acc: 0.9583\n"
     ]
    }
   ],
   "source": [
    "#Calculating accuracy for Three hidden layers NN\n",
    "\n",
    "model1.fit(X_train,y_train,epochs=100)\n",
    "y_pred = model1.predict(X_test)\n",
    "\n",
    "y_test_class = np.argmax(y_test,axis=1)\n",
    "y_pred_class = np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        13\n",
      "          2       1.00      1.00      1.00         6\n",
      "\n",
      "avg / total       1.00      1.00      1.00        30\n",
      "\n",
      "[[11  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0  6]]\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of the predicted values from Model2 with three hidden layers\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test_class,y_pred_class))\n",
    "print(confusion_matrix(y_test_class,y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
